{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7fHL3ONZ55I-"
   },
   "source": [
    "# Lab_05 Validation\n",
    "### Context\n",
    "#### Cross Validation\n",
    "+ The Set of Train, Valid, Test \n",
    "+ k-Fold with Stratify\n",
    "+ Cross Validation Score\n",
    "\n",
    "#### Parameter Tuning\n",
    "+ Grid Search\n",
    "+ Random Search\n",
    "\n",
    "#### Ensemble\n",
    "+ Voting Ensemble\n",
    "+ Stacking, Average Blending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dng6Tegg6eNc"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import join\n",
    "import copy\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sklearn\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "adult_path = join('data', 'adult_data.csv')\n",
    "column_path = join('data', 'adult_names.txt')\n",
    "\n",
    "adult_columns = list()\n",
    "for l in open(column_path):\n",
    "    adult_columns = l.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(adult_path, names = adult_columns)\n",
    "label = data['income']\n",
    "\n",
    "del data['income']\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas get_dummies 함수를 사용해 범주형 변수를 One-Hot Encoding하고, 라벨 데이터를 0,1 로 변경하겠습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.get_dummies(data)\n",
    "label = label.map(lambda x : 0 if x =='>50K' else 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation\n",
    "### 1. Train, Valid, Test Set\n",
    "훈련, 검증, 테스트 데이터라고 부르는 3가지를 한번 이야기 해보겠습니다.<br>\n",
    "* Train Data : 모델을 학습하는데 사용하는 데이터 (모델이 알고 있는 학습할 데이터)\n",
    "* Valid Data : 학습한 모델의 성능을 검증하는 데이터 (모델이 모르는 학습하지 않을 데이터, 모델 검증에 사용하는 데이터)\n",
    "* Test Data : 학습한 모델로 예측할 데이터 (모델이 모르는 예측할 데이터)\n",
    "\n",
    "<img src='./img/train_val_test.png' style='height : 500px' >\n",
    "\n",
    "\n",
    "머신러닝에서 Validation 데이터가 왜 필요한지에 대한 부분은 참조 링크를 남겨두었으니 확인하시면 좋겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# (Train, Valid), Test 분할\n",
    "# x, x_test, y, y_test = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train, Valid 분할\n",
    "# x_train, x_valid, y_train, y_valid = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# lr = LogisticRegression(random_state=2019)\n",
    "# Train 데이터로 학습\n",
    "# lr.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valid 데이터로 검증\n",
    "# y_pred_val = \n",
    "print('로지스틱 회귀 검증 데이터 정확도 :  {:.2f}%'.format(accuracy_score(y_valid, y_pred_val)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 데이터로 모델 평가\n",
    "# y_pred = \n",
    "print('로지스틱 회귀 테스트 데이터 정확도 : {:.2f}%'.format(accuracy_score(y_test, y_pred)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. k-fold with stratify\n",
    "k-fold는 데이터를 k개로 쪼개는 것을 말합니다. <br>\n",
    "일반적으로 Cross Validation에서 사용되며, 데이터셋을 k개로 쪼개어 k-1개로 모델을 학습하고, 1개로 모델을 검증합니다. <br>\n",
    "k개로 데이터를 쪼개면, 모든 fold에 대해(하나의 fold를 선택하여) 검증하는 방식으로 k번 다른 데이터셋으로 학습한 모델을 검증할 수 있습니다.\n",
    "\n",
    "![kfold](./img/kfold.png)\n",
    "\n",
    "#### Stratify, 계층적 k-fold는 뭔가요?\n",
    "k-fold는 데이터의 정렬 유무와 분류할 클래스의 비율에 상관없이 순서대로 데이터를 분할하는 특징이 있습니다.<br>\n",
    "하지만, 분류할 클래스의 비율이 다르다면 어떻게 될까요? 그런 경우에는, 각 fold가 학습 데이터셋을 대표한다고 말하기 어려워집니다.<br>\n",
    "한 fold에 특정 클래스가 많이 나올수도, 적게 나올수도 있기 때문입니다. Stratified k-fold는 그러한 문제점을 해결하기 위해 제안되었습니다.<br>\n",
    "k개의 fold도 분할한 이후에도, 전체 훈련 데이터의 클래스 비율과 각 fold가 가지고 있는 클래스의 비율을 맞추어 준다는 점이 기존의 k-fold와의 다른 특징 입니다. \n",
    "\n",
    "##### k-fold\n",
    "![kfold_example](./img/kfold_example.png)\n",
    "\n",
    "##### Stratified k-fold\n",
    "![stratified_kfold_example](./img/stratified_kfold_example.png)\n",
    "\n",
    "k-fold 실습을 위해 iris 데이터를 불러오겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "\n",
    "kf_data = iris.data\n",
    "kf_label = iris.target\n",
    "kf_columns = iris.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf_data = pd.DataFrame(kf_data, columns = kf_columns)\n",
    "kf_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### k-Fold\n",
    "k-fold는 말 그대로 데이터를 k개로 쪼갭니다. <br>\n",
    "k의 개수를 조절하여 몇개의 fold를 만들지 결정할 수 있습니다.\n",
    "\n",
    "k-fold는 sklearn의 model_selection 패키지에 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn\n",
    "# kf = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, (trn_idx, val_idx) in enumerate() :\n",
    "#     trn_data, trn_label = \n",
    "#     val_data, val_label =\n",
    "    \n",
    "#     print('{} Fold, trn label\\n {}'.format(i, trn_label))\n",
    "#     print('{} Fold, val label\\n {}\\n'.format(i, val_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### stratify k-Fold\n",
    "\n",
    "Stratified k-fold는 sklearn의 model_selection 패키지에 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn\n",
    "# skf = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, (trn_idx, val_idx) in enumerate() :\n",
    "#     trn_data, trn_label = \n",
    "#     val_data, val_label = \n",
    "    \n",
    "#     print('{} Fold, trn label\\n {}'.format(i, trn_label))\n",
    "#     print('{} Fold, val label\\n {}\\n'.format(i, val_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross Validation 해보기\n",
    "Stratified k-fold를 이용해 Cross Validation을 진행해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# val_scores = \n",
    "\n",
    "# for i, (trn_idx, val_idx) in enumerate() :\n",
    "#     trn_data, trn_label = \n",
    "#     val_data, val_label = \n",
    "    \n",
    "#     # 모델 정의\n",
    "#     clf = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=2019)\n",
    "    \n",
    "#     # 모델 학습\n",
    "#     clf.\n",
    "\n",
    "#     # 훈련, 검증 데이터 정확도 확인\n",
    "#     trn_acc = clf.\n",
    "#     val_acc = clf.\n",
    "#     print('{} Fold, train Accuracy : {:.2f}%, validation Accuracy : {:.2f}%'.format(i, trn_acc, val_acc))\n",
    "    \n",
    "#     val_scores.append(val_acc)\n",
    "\n",
    "# 교차 검증 정확도 평균 계산하기\n",
    "# print('Cross Validation Score : {:.2f}%'.format(np.mean(val_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross Validation Score\n",
    "방금 전 반복문을 사용해 Cross Validation을 진행해 봤습니다. <br>\n",
    "그런데 Sklearn에는 한번에 k-fold Cross Validation Score를 계산하는 cross_val_score 함수를 제공합니다. <br>\n",
    "파라미터로 cv에 숫자를 전달하면, 그 숫자 만큼의 fold를 만들어 Cross Validation(CV)을 진행하고, kfold 객체를 전달하면 해당 객체에 맞게 데이터를 분할하여 CV Score를 계산합니다.<br>\n",
    "cross_val_score 함수는 폴드 개수대로 Score를 반환하며, 해당 스코어들의 평균을 계산해 모델의 성능을 가늠해볼 수 있습니다.<br>\n",
    "\n",
    "* 기본적으로 cross_val_score 함수는 입력 Label 값이 클래스로 나누어진 분류 모델인 경우 StratifiedKFold를 적용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 숫자로 전달하는 경우\n",
    "# print('랜덤 포레스트 k-Fold CV Score(Acc) : {:.2f}%'.format()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fold 객체를 전달하는 경우\n",
    "# print('랜덤 포레스트 k-Fold CV Score(Acc) : {:.2f}%'.format()\n",
    "# print('랜덤 포레스트 Stratify k-Fold CV Score(Acc) : {:.2f}%'.format()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter Tuning\n",
    "### GridSearch \n",
    "모델에는 여러가지 파라미터가 들어갑니다. SVC의 경우 Soft, Hard 마진의 정도를 결정하는 'C' 커널 함수를 결정하는 'kernel' 특정 커널에서 얼마나 세세하게 볼것인지를 결정하는 'gamma' 등 <br>\n",
    "파라미터를 어떻게 결정하느냐에 따라 모델이 잘 학습하거나 잘 학습하지 못하는 경우가 발생할 수 있습니다. <br>\n",
    "Sklearn에서 가장 쉽게 제공하는 파라미터 튜닝 함수로 GridSearchCV 라는 함수가 있습니다. 해당 함수에 각 파라미터에 사용할 수치 리스트를 전달하면, 해당 함수는 파라미터들의 조합을 모두 시도해보며,<br>\n",
    "가장 좋은 성능의 파라미터를 찾게 됩니다. \n",
    "\n",
    "간단히 GridSearchCV 함수를 사용해 랜덤 포레스트의 n_estimator, max_depth 파라미터 중 가장 좋은 파라미터 조합을 찾아보겠습니다.<br>\n",
    "GridSearchCV 함수는 Sklearn의 model_selection 패키지에 있습니다.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) 모델 정의 및 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.\n",
    "\n",
    "# params = {}\n",
    "\n",
    "# clf = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) 모델 학습하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3,4) 예측 및 결과 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('GridSearchCV best score : {:.2f}%, best_params : {}'.format(clf.best_score_*100, clf.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scikit-Optimize\n",
    "GridSearch의 단점은 사용자가 직접 파라미터에 들어갈 값들의 리스트를 지정해주어야 한다는 단점이 있습니다.<br>\n",
    "Sklearn 라이브러리 내에 존재하지는 않지만, Scikit-Optimize(이하, skopt)라는 라이브러리를 간단히 소개해 드리겠습니다.<br>\n",
    "skopt는 각 파라미터에 들어갈 값들의 최대, 최소 범위를 결정해주고 파라미터 값의 분포 스케일을 결정해주어 파라미터 튜닝을 자동화 시켜주는 라이브러리입니다.<br>\n",
    "참조 링크에 Skopt 링크 남겨드리니 확인해보시면 좋겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble\n",
    "개인적으로 앙상블은 머신러닝의 꽃이라고 생각합니다. 단일 모델로 좋은 성능을 이끄는 것도 중요하지만, 서로 다른 모델의 다양성을 고려하여 결과를 이끌어내는 앙상블은 응용할 수 있는 방법이 매우 많습니다. <br>\n",
    "그 중 대표적인 3가지 앙상블에 대해 실습하고 배워보도록 하겠습니다. \n",
    "\n",
    "### 1. Voting Ensemble\n",
    "이름에서 알 수 있듯이 각자의 모델이 투표를 하여 클래스를 선택하는 방식의 앙상블 입니다. <br>\n",
    "Voting 앙상블은 Sklearn 자체적으로 모델로써 지원을 하며, 사용하기도 매우 쉽습니다. <br>\n",
    "\n",
    "다시 Adult 데이터셋으로 돌아와 앙상블을 통해 기존 단일 모델보다 좋은 결과를 얻어보도록 하겠습니다.\n",
    "\n",
    "Voting Classifier는 Sklearn의 ensemble 패키지에 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) 모델 불러오기 및 정의하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.\n",
    "# clfs = \n",
    "\n",
    "# vote_clf = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) 모델 학습하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vote_clf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Cross Validation Acc : {:.2f}%'.format(vote_clf.score(x_valid, y_valid)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) 결과 예측하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = vote_clf."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4) 결과 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Voting Ensemble Acc : {:.2f}%'.format(vote_clf.score(x_test, y_test)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Stacking, Average Blending\n",
    "앙상블 기법 중 캐글에서 가장 많이 사용되는 기법이면서 쉬운 기법입니다. Average Blending에서 회귀의 경우 각 모델들이 예측한 결과 값을 n으로 나누어 합칩니다.<br>\n",
    "분류의 경우에는 각 클래스에 해당하는 확률을 n으로 나누어 합치고, 그 중 가장 높은 확률 값을 갖는 클래스를 택하는 방식입니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단일 모델에서의 Random Forest 성능\n",
    "clf = RandomForestClassifier(n_estimators=50, max_depth=5, random_state=2019)\n",
    "clf.fit(x_train, y_train)\n",
    "print('Single Random Forest Acc : {:.2f}%'.format(clf.score(x_test, y_test)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_scores = list()\n",
    "\n",
    "# y_pred = \n",
    "\n",
    "# for i, (trn_idx, val_idx) in enumerate() :\n",
    "#     trn_data, trn_label = \n",
    "#     val_data, val_label = \n",
    "    \n",
    "#     # 모델 정의\n",
    "#     clf = RandomForestClassifier(n_estimators=50, max_depth=5, random_state=2019)\n",
    "    \n",
    "#     # 모델 학습\n",
    "#     clf.\n",
    "#     trn_acc = clf.\n",
    "#     val_acc = clf.s\n",
    "#     print('{} Fold, train Accuracy : {:.2f}%, validation Accuracy : {:.2f}%'.format(i, trn_acc, val_acc))\n",
    "    \n",
    "#     val_scores.append(val_acc)\n",
    "#     y_pred += \n",
    "    \n",
    "# # Mean Validation Score\n",
    "# print('Cross Validation Score : {:.2f}%'.format(np.mean(val_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 확률을 이진 라벨로 변경해줍니다.\n",
    "y_pred = [0 if y < 0.5 else 1 for y in y_pred]\n",
    "print('Average Blending Acc : {:.2f}%'.format(accuracy_score(y_test, y_pred)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reference\n",
    "- Validation 데이터가 필요한 이유 : https://3months.tistory.com/118\n",
    "- Sklearn, KFold : https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html\n",
    "- Sklearn, StratifedKFold : https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html#sklearn.model_selection.StratifiedKFold\n",
    "- Sklearn, Compare with KFold, StratifedKFold : https://scikit-learn.org/stable/auto_examples/model_selection/plot_cv_indices.html#sphx-glr-auto-examples-model-selection-plot-cv-indices-py\n",
    "- Sklearn, Cross Validation Score : https://www.google.com/url?q=http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html&sa=U&ved=0ahUKEwiGxeHhqubhAhUKV7wKHbFhDrcQFggEMAA&client=internal-uds-cse&cx=016639176250731907682:tjtqbvtvij0&usg=AOvVaw0rIHEJ1ltDaghFv1bvPeRO\n",
    "- Sklearn, GridSearchCV : https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\n",
    "- Sklearn, Voting Classifier : https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html\n",
    "- Scikit-Optimize, Documentation : https://scikit-optimize.github.io "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Lab_05) Model Validation.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
